{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime\n",
    "from torch.utils.data import Dataset\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from Datasets.Dataset import Dataset,Scale,ToTensor,visualize_loader,Normalize,ToLmdb\n",
    "from Models.Facenet import Resnet34Triplet\n",
    "from Models.M2FPA import load_model,save_model,set_requires_grad\\\n",
    ",init_weights,Discriminator,ParserDiscriminator,Generator\n",
    "# from Models.AlternateGenerator import Generator\n",
    "from Models.Bisnet import BiSeNet,vis_parsing_maps,re_normalize_batch,ParserMaps\n",
    "from Losses import TVLoss,DetectionLoss\n",
    "import skimage\n",
    "from skimage.io import imread,imsave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-04c3203dfbee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         )\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "env = lmdb.open(\n",
    "            'Utils/Train.lmdb',\n",
    "            max_readers=32,\n",
    "            readonly=True,\n",
    "            lock=False,\n",
    "            readahead=False,\n",
    "            meminit=False,\n",
    "        )\n",
    "with env.begin(write=False) as txn:\n",
    "    length = int(txn.get('length'.encode('utf-8')).decode('utf-8'))\n",
    "print(length)\n",
    "with env.begin(write=False) as txn:\n",
    "    key = '{}'.format(str(3).zfill(3)).encode('utf-8')\n",
    "    img_bytes = txn.get(key)\n",
    "    \n",
    "buffer = BytesIO(img_bytes)\n",
    "img_re=np.load(buffer)\n",
    "print(img_re.shape)\n",
    "plt.imshow(img_re[0]);plt.show()\n",
    "plt.imshow(img_re[1]);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "    \n",
    "    \n",
    "BATCH_SIZE=16\n",
    "START_EPOCHS=0\n",
    "END_EPOCHS=10\n",
    "CRITIC_ITER=10\n",
    "\n",
    "\n",
    "LAMBDA_PIXEL=20\n",
    "LAMBDA_DETECT=0.08\n",
    "LAMBDA_ADV_PARSER=1\n",
    "LAMBDA_TV=1e-4\n",
    "LAMBDA_ADV=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF BATCHES :  16160\n"
     ]
    }
   ],
   "source": [
    "transform=ToLmdb()#torchvision.transforms.Compose([Scale(),ToTensor(),Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "train_dataset=Dataset('M2FPA_TRAIN.csv',transform)\n",
    "train_loader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "NO_STEPS=train_dataset.__len__()//BATCH_SIZE\n",
    "print(\"NUMBER OF BATCHES : \",train_loader.__len__())\n",
    "x=next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n",
      "torch.Size([2, 512, 512, 3])\n"
     ]
    }
   ],
   "source": [
    "for y in x:\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image,gt_image=visualize_loader(train_loader,index=1)\n",
    "print(\"MAX VALUE : \",\"\\ninput_image\",np.max(input_image),\"\\ngt_image\",np.max(gt_image))\n",
    "print(\"MIN VALUE : \",\"\\ninput_image\",np.min(input_image),\"\\ngt_image\",np.min(gt_image))\n",
    "print(\"IMG SIZE : \",\"\\ninput_image\",input_image.shape,\"\\ngt_image\",gt_image.shape)\n",
    "plt.imshow(input_image);plt.show()\n",
    "plt.imshow(gt_image);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_parser=BiSeNet(19)\n",
    "load_model('Weights/Parser.pth',model_parser)\n",
    "model_detect=Resnet34Triplet()\n",
    "load_model('Weights/Facenet.pth',model_detect)\n",
    "modelG=Generator()#(norm='batch',activation='lrelu')\n",
    "init_weights(modelG)\n",
    "modelD=Discriminator(norm='batch',activation='lrelu')\n",
    "init_weights(modelD)\n",
    "modelD_parser=ParserDiscriminator(norm='batch',activation='lrelu')\n",
    "init_weights(modelD_parser)\n",
    "\n",
    "model_start_date=datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
    "BEST_MODEL_PATH=os.path.join(os.getcwd(),'model_{}'.format(model_start_date))\n",
    "if not os.path.exists(BEST_MODEL_PATH):\n",
    "    os.mkdir(BEST_MODEL_PATH)\n",
    "    print('model_{} dir has been made'.format(model_start_date))\n",
    "print(\"Model's state_dict:\")\n",
    "print()\n",
    "print(color.BOLD + 'GENERATOR' + color.END)\n",
    "for param_tensor in modelG.state_dict():\n",
    "    print(param_tensor, \"\\t\", modelG.state_dict()[param_tensor].size())\n",
    "\n",
    "print(color.BOLD + 'DISCRIMINATOR' + color.END)\n",
    "for param_tensor in modelD.state_dict():\n",
    "    print(param_tensor, \"\\t\", modelD.state_dict()[param_tensor].size())\n",
    "    \n",
    "    \n",
    "print(color.BOLD + 'DISCRIMINATOR PARSER' + color.END)\n",
    "for param_tensor in modelD_parser.state_dict():\n",
    "    print(param_tensor, \"\\t\", modelD_parser.state_dict()[param_tensor].size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "modelG = modelG.to(device)\n",
    "modelD = modelD.to(device)\n",
    "modelD_parser=modelD_parser.to(device)\n",
    "\n",
    "parser_map_generator=ParserMaps(model_parser)\n",
    "\n",
    "\n",
    "model_parser.eval()\n",
    "model_detect.eval()\n",
    "modelG.train()\n",
    "modelD.train()\n",
    "modelD_parser.train()\n",
    "\n",
    "\n",
    "\n",
    "criterion_feature=DetectionLoss(model_detect).to('cuda')\n",
    "criterion_mse=torch.nn.MSELoss().to('cuda')\n",
    "criterion_tv=TVLoss().to('cuda')\n",
    "\n",
    "\n",
    "\n",
    "optimizerG = torch.optim.Adam(modelG.parameters(),lr=10e-03, betas=(0.9, 0.98),weight_decay=0.02)\n",
    "optimizerD = torch.optim.SGD(modelD.parameters(),lr=10e-03, momentum=0.8,nesterov=True)\n",
    "optimizerD_parser = torch.optim.SGD(modelD_parser.parameters(),lr=10e-03, momentum=0.8,nesterov=True)\n",
    "\n",
    "\n",
    "best_val=10e06\n",
    "\n",
    "for epoch in range(START_EPOCHS,END_EPOCHS):\n",
    "    \n",
    "    print(\"Learning Rate Generator : {}\\nLearning Rate Discriminator : {}\\nLearning Rate Discriminator 2 : {}\"\\\n",
    "          .format(optimizerG.state_dict()['param_groups'][-1]['lr'],\\\n",
    "                  optimizerD.state_dict()['param_groups'][-1]['lr'],\\\n",
    "                 optimizerD_parser.state_dict()['param_groups'][-1]['lr']))\n",
    "    gen_detect_score=0\n",
    "    gen_pixel_loss=0\n",
    "    \n",
    "  # loop over the dataset multiple times\n",
    "\n",
    "    loop=tqdm(train_loader)\n",
    "    \n",
    "    gen_train_steps=0\n",
    "\n",
    "    for i, sample_batched in (enumerate(loop)):\n",
    "        \n",
    "        loop.set_description('Epoch {}/{}'.format(epoch + 1, END_EPOCHS))\n",
    "\n",
    "        # get the inputs;\n",
    "        input_image_batch, gt_image_batch= sample_batched['input_image'],\\\n",
    "        sample_batched['gt_image']\n",
    "\n",
    "        input_image_batch, gt_image_batch = input_image_batch.to(device, dtype = torch.float)\\\n",
    "        ,gt_image_batch.to(device, dtype = torch.float)\n",
    "        \n",
    "\n",
    "        if (i+1)%CRITIC_ITER==0:\n",
    "        ## Generator training ##\n",
    "            \n",
    "            set_requires_grad(modelD, requires_grad=False)\n",
    "            set_requires_grad(modelD_parser, requires_grad=False)\n",
    "            modelG.zero_grad()\n",
    "            \n",
    "            \n",
    "            recon_front=modelG(input_image_batch)\n",
    "            Discriminator_op=modelD(recon_front)\n",
    "            x,y,z=parser_map_generator(recon_front)\n",
    "            Discriminator_parser_op=modelD_parser(x,y,z)\n",
    "\n",
    "            loss_G_detect=criterion_feature(recon_front,gt_image_batch)\n",
    "            loss_G_pixel=criterion_mse(recon_front,gt_image_batch)\n",
    "            loss_G_D=1-Discriminator_op.mean()\n",
    "            loss_G_D_parser=1-Discriminator_parser_op.mean()\n",
    "            loss_G_tv=criterion_tv(recon_front)\n",
    "            \n",
    "            loss_G=LAMBDA_PIXEL*loss_G_detect+LAMBDA_DETECT*loss_G_detect+\\\n",
    "            LAMBDA_ADV_PARSER*loss_G_D_parser+LAMBDA_TV*loss_G_tv+LAMBDA_ADV*loss_G_D\n",
    "            \n",
    "            loss_G.backward()\n",
    "            optimizerG.step()\n",
    "            \n",
    "            gen_detect_score=gen_detect_score*0.9+loss_G_detect.detach().item()*0.1\n",
    "            gen_pixel_loss=gen_pixel_loss*0.9+loss_G_pixel.detach().item()*0.1\n",
    "            \n",
    "            loop.set_postfix(Pixel_loss=gen_pixel_loss,Detection_loss=gen_detect_score)\n",
    "\n",
    "            \n",
    "            if (i+1)%500==0:\n",
    "\n",
    "                img_train = torchvision.utils.make_grid(recon_front.detach().cpu()\\\n",
    "                                                        ,nrow=BATCH_SIZE//4,padding=40)\n",
    "            \n",
    "                torchvision.utils.save_image(img_train,os.path.join(os.getcwd(),\\\n",
    "                                                                    BEST_MODEL_PATH+'/train_iter_{}.png'.\\\n",
    "                                                                    format(epoch*len(train_loader)+i+1)))\n",
    "                save_model(modelD,optimizerD,os.path.join(BEST_MODEL_PATH\\\n",
    "                                                          ,'Discriminator_{}.pth'.format\\\n",
    "                                                          (epoch*len(train_loader)+i+1)),scheduler=None)\n",
    "                save_model(modelD_parser,optimizerD_parser,os.path.join(BEST_MODEL_PATH\\\n",
    "                                                          ,'Discriminator_parser_{}.pth'.format\\\n",
    "                                                          (epoch*len(train_loader)+i+1)),scheduler=None)\n",
    "                \n",
    "                save_model(modelG,optimizerG,os.path.join(BEST_MODEL_PATH,\\\n",
    "                                                          'Generator_{}.pth'.format\\\n",
    "                                                          (epoch*len(train_loader)+i+1)),scheduler=None)\n",
    "        \n",
    "            \n",
    "        else:\n",
    "\n",
    "            #Train discriminator\n",
    "            \n",
    "\n",
    "            set_requires_grad(modelD, requires_grad=True)\n",
    "            modelD.zero_grad()\n",
    "            \n",
    "            set_requires_grad(modelD_parser, requires_grad=True)\n",
    "            modelD_parser.zero_grad()\n",
    "            \n",
    "            recon_front_D=modelG(input_image_batch)\n",
    "            \n",
    "            Discriminator_op_recon=modelD(recon_front_D)\n",
    "            Discriminator_op_gt=modelD(gt_image_batch)\n",
    "            x_recon,y_recon,z_recon=parser_map_generator(recon_front_D)\n",
    "            Discriminator_parser_op_recon=modelD_parser(x_recon,y_recon,z_recon)\n",
    "            x_gt,y_gt,z_gt=parser_map_generator(gt_image_batch)\n",
    "            Discriminator_parser_op_gt=modelD_parser(x_gt,y_gt,z_gt)\n",
    "            \n",
    "           \n",
    "            loss_D=1-Discriminator_op_recon.mean()+Discriminator_op_gt.mean()\n",
    "            loss_D_parser=1-Discriminator_parser_op_recon.mean()+Discriminator_parser_op_gt.mean()\n",
    "            \n",
    "            loss_D.backward(retain_graph=True)\n",
    "            optimizerD.step()\n",
    "            \n",
    "            loss_D_parser.backward(retain_graph=True)\n",
    "            optimizerD_parser.step()\n",
    "\n",
    "\n",
    "save_model(modelG,optimizerG,os.path.join(MODEL_PATH,'Generator_final.pth'),scheduler=None)\n",
    "print('Finished Training')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
